{"type": "server", "timestamp": "2019-07-09T07:07:36,988+1000", "level": "INFO", "component": "o.e.e.NodeEnvironment", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "using [1] data paths, mounts [[400GB (C:)]], net usable_space [162.2gb], net total_space [377.3gb], types [NTFS]"  }
{"type": "server", "timestamp": "2019-07-09T07:07:37,107+1000", "level": "INFO", "component": "o.e.e.NodeEnvironment", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "heap size [990.7mb], compressed ordinary object pointers [true]"  }
{"type": "server", "timestamp": "2019-07-09T07:07:40,021+1000", "level": "INFO", "component": "o.e.n.Node", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "node name [elasticsearch01], node ID [UX-HdPY5Q0iJLIzpq8XKpw], cluster name [mongushSIEM]"  }
{"type": "server", "timestamp": "2019-07-09T07:07:40,022+1000", "level": "INFO", "component": "o.e.n.Node", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "version[7.1.1], pid[230584], build[default/zip/7a013de/2019-05-23T14:04:00.380842Z], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/12.0.1/12.0.1+12]"  }
{"type": "server", "timestamp": "2019-07-09T07:07:40,024+1000", "level": "INFO", "component": "o.e.n.Node", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "JVM home [C:\\Program Files\\Java\\jdk-12.0.1]"  }
{"type": "server", "timestamp": "2019-07-09T07:07:40,025+1000", "level": "INFO", "component": "o.e.n.Node", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "JVM arguments [-Xms1g, -Xmx1g, -XX:+UseConcMarkSweepGC, -XX:CMSInitiatingOccupancyFraction=75, -XX:+UseCMSInitiatingOccupancyOnly, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Djava.io.tmpdir=C:\\Users\\emirm\\AppData\\Local\\Temp\\elasticsearch, -XX:+HeapDumpOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Djava.locale.providers=COMPAT, -Dio.netty.allocator.type=unpooled, -Delasticsearch, -Des.path.home=C:\\SIEM\\elasticsearch, -Des.path.conf=C:\\SIEM\\elasticsearch\\config, -Des.distribution.flavor=default, -Des.distribution.type=zip, -Des.bundled_jd=true]"  }
{"type": "server", "timestamp": "2019-07-09T07:09:16,036+1000", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "loaded module [aggs-matrix-stats]"  }
{"type": "server", "timestamp": "2019-07-09T07:09:16,037+1000", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "loaded module [analysis-common]"  }
{"type": "server", "timestamp": "2019-07-09T07:09:16,038+1000", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "loaded module [ingest-common]"  }
{"type": "server", "timestamp": "2019-07-09T07:09:16,039+1000", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "loaded module [ingest-geoip]"  }
{"type": "server", "timestamp": "2019-07-09T07:09:16,039+1000", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "loaded module [ingest-user-agent]"  }
{"type": "server", "timestamp": "2019-07-09T07:09:16,040+1000", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "loaded module [lang-expression]"  }
{"type": "server", "timestamp": "2019-07-09T07:09:16,041+1000", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "loaded module [lang-mustache]"  }
{"type": "server", "timestamp": "2019-07-09T07:09:16,042+1000", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "loaded module [lang-painless]"  }
{"type": "server", "timestamp": "2019-07-09T07:09:16,042+1000", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "loaded module [mapper-extras]"  }
{"type": "server", "timestamp": "2019-07-09T07:09:16,043+1000", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "loaded module [parent-join]"  }
{"type": "server", "timestamp": "2019-07-09T07:09:16,043+1000", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "loaded module [percolator]"  }
{"type": "server", "timestamp": "2019-07-09T07:09:16,044+1000", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "loaded module [rank-eval]"  }
{"type": "server", "timestamp": "2019-07-09T07:09:16,044+1000", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "loaded module [reindex]"  }
{"type": "server", "timestamp": "2019-07-09T07:09:16,045+1000", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "loaded module [repository-url]"  }
{"type": "server", "timestamp": "2019-07-09T07:09:16,046+1000", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "loaded module [transport-netty4]"  }
{"type": "server", "timestamp": "2019-07-09T07:09:16,047+1000", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "loaded module [x-pack-ccr]"  }
{"type": "server", "timestamp": "2019-07-09T07:09:16,047+1000", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "loaded module [x-pack-core]"  }
{"type": "server", "timestamp": "2019-07-09T07:09:16,048+1000", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "loaded module [x-pack-deprecation]"  }
{"type": "server", "timestamp": "2019-07-09T07:09:16,049+1000", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "loaded module [x-pack-graph]"  }
{"type": "server", "timestamp": "2019-07-09T07:09:16,050+1000", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "loaded module [x-pack-ilm]"  }
{"type": "server", "timestamp": "2019-07-09T07:09:16,050+1000", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "loaded module [x-pack-logstash]"  }
{"type": "server", "timestamp": "2019-07-09T07:09:16,051+1000", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "loaded module [x-pack-ml]"  }
{"type": "server", "timestamp": "2019-07-09T07:09:16,052+1000", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "loaded module [x-pack-monitoring]"  }
{"type": "server", "timestamp": "2019-07-09T07:09:16,053+1000", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "loaded module [x-pack-rollup]"  }
{"type": "server", "timestamp": "2019-07-09T07:09:16,053+1000", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "loaded module [x-pack-security]"  }
{"type": "server", "timestamp": "2019-07-09T07:09:16,054+1000", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "loaded module [x-pack-sql]"  }
{"type": "server", "timestamp": "2019-07-09T07:09:16,055+1000", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "loaded module [x-pack-watcher]"  }
{"type": "server", "timestamp": "2019-07-09T07:09:16,056+1000", "level": "INFO", "component": "o.e.p.PluginsService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "no plugins loaded"  }
{"type": "server", "timestamp": "2019-07-09T07:09:53,406+1000", "level": "INFO", "component": "o.e.x.s.a.s.FileRolesStore", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "parsed [0] roles from file [C:\\SIEM\\elasticsearch\\config\\roles.yml]"  }
{"type": "server", "timestamp": "2019-07-09T07:09:58,104+1000", "level": "INFO", "component": "o.e.x.m.p.l.CppLogMessageHandler", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "[controller/240332] [Main.cc@109] controller (64 bit): Version 7.1.1 (Build fd619a36eb77df) Copyright (c) 2019 Elasticsearch BV"  }
{"type": "server", "timestamp": "2019-07-09T07:09:59,748+1000", "level": "DEBUG", "component": "o.e.a.ActionModule", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "Using REST wrapper from plugin org.elasticsearch.xpack.security.Security"  }
{"type": "server", "timestamp": "2019-07-09T07:10:03,196+1000", "level": "INFO", "component": "o.e.d.DiscoveryModule", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "using discovery type [zen] and seed hosts providers [settings]"  }
{"type": "server", "timestamp": "2019-07-09T07:10:06,768+1000", "level": "INFO", "component": "o.e.n.Node", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "initialized"  }
{"type": "server", "timestamp": "2019-07-09T07:10:06,769+1000", "level": "INFO", "component": "o.e.n.Node", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "starting ..."  }
{"type": "server", "timestamp": "2019-07-09T07:10:10,024+1000", "level": "INFO", "component": "o.e.t.TransportService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}"  }
{"type": "server", "timestamp": "2019-07-09T07:10:10,217+1000", "level": "WARN", "component": "o.e.b.BootstrapChecks", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured"  }
{"type": "server", "timestamp": "2019-07-09T07:10:10,235+1000", "level": "INFO", "component": "o.e.c.c.Coordinator", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "cluster UUID [0Iesw0zBRS25JqFdm-TcLQ]"  }
{"type": "server", "timestamp": "2019-07-09T07:10:10,295+1000", "level": "INFO", "component": "o.e.c.c.ClusterBootstrapService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "no discovery configuration found, will perform best-effort cluster bootstrapping after [3s] unless existing master is discovered"  }
{"type": "server", "timestamp": "2019-07-09T07:10:10,947+1000", "level": "INFO", "component": "o.e.c.s.MasterService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "elected-as-master ([1] nodes joined)[{elasticsearch01}{UX-HdPY5Q0iJLIzpq8XKpw}{-gO45oUTRM-rWV0mgrjwqQ}{127.0.0.1}{127.0.0.1:9300}{ml.machine_memory=6248751104, xpack.installed=true, ml.max_open_jobs=20} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 6, version: 248, reason: master node changed {previous [], current [{elasticsearch01}{UX-HdPY5Q0iJLIzpq8XKpw}{-gO45oUTRM-rWV0mgrjwqQ}{127.0.0.1}{127.0.0.1:9300}{ml.machine_memory=6248751104, xpack.installed=true, ml.max_open_jobs=20}]}"  }
{"type": "server", "timestamp": "2019-07-09T07:10:16,242+1000", "level": "INFO", "component": "o.e.c.s.ClusterApplierService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01",  "message": "master node changed {previous [], current [{elasticsearch01}{UX-HdPY5Q0iJLIzpq8XKpw}{-gO45oUTRM-rWV0mgrjwqQ}{127.0.0.1}{127.0.0.1:9300}{ml.machine_memory=6248751104, xpack.installed=true, ml.max_open_jobs=20}]}, term: 6, version: 248, reason: Publication{term=6, version=248}"  }
{"type": "server", "timestamp": "2019-07-09T07:10:16,712+1000", "level": "INFO", "component": "o.e.c.s.ClusterSettings", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "updating [xpack.monitoring.collection.enabled] from [false] to [true]"  }
{"type": "server", "timestamp": "2019-07-09T07:10:18,623+1000", "level": "INFO", "component": "o.e.h.AbstractHttpServerTransport", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}"  }
{"type": "server", "timestamp": "2019-07-09T07:10:18,626+1000", "level": "INFO", "component": "o.e.n.Node", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "started"  }
{"type": "server", "timestamp": "2019-07-09T07:10:24,901+1000", "level": "WARN", "component": "o.e.x.s.a.s.m.NativeRoleMappingStore", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "Failed to clear cache for realms [[]]"  }
{"type": "server", "timestamp": "2019-07-09T07:10:25,447+1000", "level": "INFO", "component": "o.e.l.LicenseService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "license [429af80b-2afa-43f3-b0be-400042b3e335] mode [basic] - valid"  }
{"type": "server", "timestamp": "2019-07-09T07:10:25,791+1000", "level": "INFO", "component": "o.e.g.GatewayService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "recovered [17] indices into cluster_state"  }
{"type": "server", "timestamp": "2019-07-09T07:10:30,691+1000", "level": "INFO", "component": "o.e.c.m.MetaDataCreateIndexService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "[.monitoring-es-7-2019.07.08] creating index, cause [auto(bulk api)], templates [.monitoring-es], shards [1]/[0], mappings [_doc]"  }
{"type": "server", "timestamp": "2019-07-09T07:11:02,382+1000", "level": "INFO", "component": "o.e.c.r.a.AllocationService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[winlogbeat-7.1.0-2019.06.10-000001][0]] ...])."  }
{"type": "server", "timestamp": "2019-07-09T07:12:31,976+1000", "level": "INFO", "component": "o.e.c.m.MetaDataIndexTemplateService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "adding template [.management-beats] for index patterns [.management-beats]"  }
{"type": "server", "timestamp": "2019-07-09T07:12:35,084+1000", "level": "INFO", "component": "o.e.c.m.MetaDataCreateIndexService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "[.monitoring-kibana-7-2019.07.08] creating index, cause [auto(bulk api)], templates [.monitoring-kibana], shards [1]/[0], mappings [_doc]"  }
{"type": "server", "timestamp": "2019-07-09T08:29:52,295+1000", "level": "WARN", "component": "o.e.h.AbstractHttpServerTransport", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "caught exception while handling client http traffic, closing connection Netty4HttpChannel{localAddress=/0:0:0:0:0:0:0:1:9200, remoteAddress=/0:0:0:0:0:0:0:1:43816}" , 
"stacktrace": ["java.io.IOException: Удаленный хост принудительно разорвал существующее подключение",
"at sun.nio.ch.SocketDispatcher.read0(Native Method) ~[?:?]",
"at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43) ~[?:?]",
"at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276) ~[?:?]",
"at sun.nio.ch.IOUtil.read(IOUtil.java:245) ~[?:?]",
"at sun.nio.ch.IOUtil.read(IOUtil.java:223) ~[?:?]",
"at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358) ~[?:?]",
"at io.netty.buffer.UnpooledHeapByteBuf.setBytes(UnpooledHeapByteBuf.java:291) ~[netty-buffer-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132) ~[netty-buffer-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:347) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:656) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:556) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:510) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:470) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:909) [netty-common-4.1.32.Final.jar:4.1.32.Final]",
"at java.lang.Thread.run(Thread.java:835) [?:?]"] }
{"type": "server", "timestamp": "2019-07-09T08:29:52,295+1000", "level": "WARN", "component": "o.e.h.AbstractHttpServerTransport", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "caught exception while handling client http traffic, closing connection Netty4HttpChannel{localAddress=/0:0:0:0:0:0:0:1:9200, remoteAddress=/0:0:0:0:0:0:0:1:43642}" , 
"stacktrace": ["java.io.IOException: Удаленный хост принудительно разорвал существующее подключение",
"at sun.nio.ch.SocketDispatcher.read0(Native Method) ~[?:?]",
"at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43) ~[?:?]",
"at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276) ~[?:?]",
"at sun.nio.ch.IOUtil.read(IOUtil.java:245) ~[?:?]",
"at sun.nio.ch.IOUtil.read(IOUtil.java:223) ~[?:?]",
"at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358) ~[?:?]",
"at io.netty.buffer.UnpooledHeapByteBuf.setBytes(UnpooledHeapByteBuf.java:291) ~[netty-buffer-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132) ~[netty-buffer-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:347) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:656) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:556) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:510) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:470) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:909) [netty-common-4.1.32.Final.jar:4.1.32.Final]",
"at java.lang.Thread.run(Thread.java:835) [?:?]"] }
{"type": "server", "timestamp": "2019-07-09T08:29:52,295+1000", "level": "WARN", "component": "o.e.h.AbstractHttpServerTransport", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "caught exception while handling client http traffic, closing connection Netty4HttpChannel{localAddress=/0:0:0:0:0:0:0:1:9200, remoteAddress=/0:0:0:0:0:0:0:1:43613}" , 
"stacktrace": ["java.io.IOException: Удаленный хост принудительно разорвал существующее подключение",
"at sun.nio.ch.SocketDispatcher.read0(Native Method) ~[?:?]",
"at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43) ~[?:?]",
"at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276) ~[?:?]",
"at sun.nio.ch.IOUtil.read(IOUtil.java:245) ~[?:?]",
"at sun.nio.ch.IOUtil.read(IOUtil.java:223) ~[?:?]",
"at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358) ~[?:?]",
"at io.netty.buffer.UnpooledHeapByteBuf.setBytes(UnpooledHeapByteBuf.java:291) ~[netty-buffer-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132) ~[netty-buffer-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:347) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:656) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:556) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:510) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:470) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:909) [netty-common-4.1.32.Final.jar:4.1.32.Final]",
"at java.lang.Thread.run(Thread.java:835) [?:?]"] }
{"type": "server", "timestamp": "2019-07-09T08:29:52,295+1000", "level": "WARN", "component": "o.e.h.AbstractHttpServerTransport", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "caught exception while handling client http traffic, closing connection Netty4HttpChannel{localAddress=/0:0:0:0:0:0:0:1:9200, remoteAddress=/0:0:0:0:0:0:0:1:43856}" , 
"stacktrace": ["java.io.IOException: Удаленный хост принудительно разорвал существующее подключение",
"at sun.nio.ch.SocketDispatcher.read0(Native Method) ~[?:?]",
"at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43) ~[?:?]",
"at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276) ~[?:?]",
"at sun.nio.ch.IOUtil.read(IOUtil.java:245) ~[?:?]",
"at sun.nio.ch.IOUtil.read(IOUtil.java:223) ~[?:?]",
"at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358) ~[?:?]",
"at io.netty.buffer.UnpooledHeapByteBuf.setBytes(UnpooledHeapByteBuf.java:291) ~[netty-buffer-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132) ~[netty-buffer-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:347) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:656) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:556) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:510) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:470) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:909) [netty-common-4.1.32.Final.jar:4.1.32.Final]",
"at java.lang.Thread.run(Thread.java:835) [?:?]"] }
{"type": "server", "timestamp": "2019-07-09T08:29:52,295+1000", "level": "WARN", "component": "o.e.h.AbstractHttpServerTransport", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "caught exception while handling client http traffic, closing connection Netty4HttpChannel{localAddress=/0:0:0:0:0:0:0:1:9200, remoteAddress=/0:0:0:0:0:0:0:1:43423}" , 
"stacktrace": ["java.io.IOException: Удаленный хост принудительно разорвал существующее подключение",
"at sun.nio.ch.SocketDispatcher.read0(Native Method) ~[?:?]",
"at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43) ~[?:?]",
"at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276) ~[?:?]",
"at sun.nio.ch.IOUtil.read(IOUtil.java:245) ~[?:?]",
"at sun.nio.ch.IOUtil.read(IOUtil.java:223) ~[?:?]",
"at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358) ~[?:?]",
"at io.netty.buffer.UnpooledHeapByteBuf.setBytes(UnpooledHeapByteBuf.java:291) ~[netty-buffer-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132) ~[netty-buffer-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:347) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:656) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:556) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:510) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:470) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:909) [netty-common-4.1.32.Final.jar:4.1.32.Final]",
"at java.lang.Thread.run(Thread.java:835) [?:?]"] }
{"type": "server", "timestamp": "2019-07-09T08:29:52,295+1000", "level": "WARN", "component": "o.e.h.AbstractHttpServerTransport", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "caught exception while handling client http traffic, closing connection Netty4HttpChannel{localAddress=/0:0:0:0:0:0:0:1:9200, remoteAddress=/0:0:0:0:0:0:0:1:43579}" , 
"stacktrace": ["java.io.IOException: Удаленный хост принудительно разорвал существующее подключение",
"at sun.nio.ch.SocketDispatcher.read0(Native Method) ~[?:?]",
"at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43) ~[?:?]",
"at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276) ~[?:?]",
"at sun.nio.ch.IOUtil.read(IOUtil.java:245) ~[?:?]",
"at sun.nio.ch.IOUtil.read(IOUtil.java:223) ~[?:?]",
"at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358) ~[?:?]",
"at io.netty.buffer.UnpooledHeapByteBuf.setBytes(UnpooledHeapByteBuf.java:291) ~[netty-buffer-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132) ~[netty-buffer-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:347) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:656) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:556) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:510) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:470) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:909) [netty-common-4.1.32.Final.jar:4.1.32.Final]",
"at java.lang.Thread.run(Thread.java:835) [?:?]"] }
{"type": "server", "timestamp": "2019-07-09T08:29:52,295+1000", "level": "WARN", "component": "o.e.h.AbstractHttpServerTransport", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "caught exception while handling client http traffic, closing connection Netty4HttpChannel{localAddress=/0:0:0:0:0:0:0:1:9200, remoteAddress=/0:0:0:0:0:0:0:1:43421}" , 
"stacktrace": ["java.io.IOException: Удаленный хост принудительно разорвал существующее подключение",
"at sun.nio.ch.SocketDispatcher.read0(Native Method) ~[?:?]",
"at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43) ~[?:?]",
"at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276) ~[?:?]",
"at sun.nio.ch.IOUtil.read(IOUtil.java:245) ~[?:?]",
"at sun.nio.ch.IOUtil.read(IOUtil.java:223) ~[?:?]",
"at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358) ~[?:?]",
"at io.netty.buffer.UnpooledHeapByteBuf.setBytes(UnpooledHeapByteBuf.java:291) ~[netty-buffer-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132) ~[netty-buffer-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:347) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:656) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:556) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:510) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:470) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:909) [netty-common-4.1.32.Final.jar:4.1.32.Final]",
"at java.lang.Thread.run(Thread.java:835) [?:?]"] }
{"type": "server", "timestamp": "2019-07-09T08:29:54,388+1000", "level": "WARN", "component": "o.e.h.AbstractHttpServerTransport", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "caught exception while handling client http traffic, closing connection Netty4HttpChannel{localAddress=/0:0:0:0:0:0:0:1:9200, remoteAddress=/0:0:0:0:0:0:0:1:43453}" , 
"stacktrace": ["java.io.IOException: Удаленный хост принудительно разорвал существующее подключение",
"at sun.nio.ch.SocketDispatcher.read0(Native Method) ~[?:?]",
"at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43) ~[?:?]",
"at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276) ~[?:?]",
"at sun.nio.ch.IOUtil.read(IOUtil.java:245) ~[?:?]",
"at sun.nio.ch.IOUtil.read(IOUtil.java:223) ~[?:?]",
"at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358) ~[?:?]",
"at io.netty.buffer.UnpooledHeapByteBuf.setBytes(UnpooledHeapByteBuf.java:291) ~[netty-buffer-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132) ~[netty-buffer-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:347) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:656) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:556) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:510) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:470) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:909) [netty-common-4.1.32.Final.jar:4.1.32.Final]",
"at java.lang.Thread.run(Thread.java:835) [?:?]"] }
{"type": "server", "timestamp": "2019-07-09T08:29:54,399+1000", "level": "WARN", "component": "o.e.h.AbstractHttpServerTransport", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "caught exception while handling client http traffic, closing connection Netty4HttpChannel{localAddress=/0:0:0:0:0:0:0:1:9200, remoteAddress=/0:0:0:0:0:0:0:1:43747}" , 
"stacktrace": ["java.io.IOException: Удаленный хост принудительно разорвал существующее подключение",
"at sun.nio.ch.SocketDispatcher.read0(Native Method) ~[?:?]",
"at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43) ~[?:?]",
"at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276) ~[?:?]",
"at sun.nio.ch.IOUtil.read(IOUtil.java:245) ~[?:?]",
"at sun.nio.ch.IOUtil.read(IOUtil.java:223) ~[?:?]",
"at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358) ~[?:?]",
"at io.netty.buffer.UnpooledHeapByteBuf.setBytes(UnpooledHeapByteBuf.java:291) ~[netty-buffer-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132) ~[netty-buffer-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:347) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:656) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:556) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:510) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:470) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:909) [netty-common-4.1.32.Final.jar:4.1.32.Final]",
"at java.lang.Thread.run(Thread.java:835) [?:?]"] }
{"type": "server", "timestamp": "2019-07-09T08:29:54,405+1000", "level": "WARN", "component": "o.e.h.AbstractHttpServerTransport", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "caught exception while handling client http traffic, closing connection Netty4HttpChannel{localAddress=/0:0:0:0:0:0:0:1:9200, remoteAddress=/0:0:0:0:0:0:0:1:43718}" , 
"stacktrace": ["java.io.IOException: Удаленный хост принудительно разорвал существующее подключение",
"at sun.nio.ch.SocketDispatcher.read0(Native Method) ~[?:?]",
"at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43) ~[?:?]",
"at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276) ~[?:?]",
"at sun.nio.ch.IOUtil.read(IOUtil.java:245) ~[?:?]",
"at sun.nio.ch.IOUtil.read(IOUtil.java:223) ~[?:?]",
"at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358) ~[?:?]",
"at io.netty.buffer.UnpooledHeapByteBuf.setBytes(UnpooledHeapByteBuf.java:291) ~[netty-buffer-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132) ~[netty-buffer-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:347) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:656) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:556) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:510) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:470) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:909) [netty-common-4.1.32.Final.jar:4.1.32.Final]",
"at java.lang.Thread.run(Thread.java:835) [?:?]"] }
{"type": "server", "timestamp": "2019-07-09T08:29:54,394+1000", "level": "WARN", "component": "o.e.h.AbstractHttpServerTransport", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "caught exception while handling client http traffic, closing connection Netty4HttpChannel{localAddress=/0:0:0:0:0:0:0:1:9200, remoteAddress=/0:0:0:0:0:0:0:1:43516}" , 
"stacktrace": ["java.io.IOException: Удаленный хост принудительно разорвал существующее подключение",
"at sun.nio.ch.SocketDispatcher.read0(Native Method) ~[?:?]",
"at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43) ~[?:?]",
"at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276) ~[?:?]",
"at sun.nio.ch.IOUtil.read(IOUtil.java:245) ~[?:?]",
"at sun.nio.ch.IOUtil.read(IOUtil.java:223) ~[?:?]",
"at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358) ~[?:?]",
"at io.netty.buffer.UnpooledHeapByteBuf.setBytes(UnpooledHeapByteBuf.java:291) ~[netty-buffer-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132) ~[netty-buffer-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:347) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:656) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:556) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:510) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:470) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:909) [netty-common-4.1.32.Final.jar:4.1.32.Final]",
"at java.lang.Thread.run(Thread.java:835) [?:?]"] }
{"type": "server", "timestamp": "2019-07-09T08:29:54,392+1000", "level": "WARN", "component": "o.e.h.AbstractHttpServerTransport", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "caught exception while handling client http traffic, closing connection Netty4HttpChannel{localAddress=/0:0:0:0:0:0:0:1:9200, remoteAddress=/0:0:0:0:0:0:0:1:43544}" , 
"stacktrace": ["java.io.IOException: Удаленный хост принудительно разорвал существующее подключение",
"at sun.nio.ch.SocketDispatcher.read0(Native Method) ~[?:?]",
"at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43) ~[?:?]",
"at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276) ~[?:?]",
"at sun.nio.ch.IOUtil.read(IOUtil.java:245) ~[?:?]",
"at sun.nio.ch.IOUtil.read(IOUtil.java:223) ~[?:?]",
"at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358) ~[?:?]",
"at io.netty.buffer.UnpooledHeapByteBuf.setBytes(UnpooledHeapByteBuf.java:291) ~[netty-buffer-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132) ~[netty-buffer-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:347) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:656) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:556) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:510) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:470) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:909) [netty-common-4.1.32.Final.jar:4.1.32.Final]",
"at java.lang.Thread.run(Thread.java:835) [?:?]"] }
{"type": "server", "timestamp": "2019-07-09T08:29:54,389+1000", "level": "WARN", "component": "o.e.h.AbstractHttpServerTransport", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "caught exception while handling client http traffic, closing connection Netty4HttpChannel{localAddress=/0:0:0:0:0:0:0:1:9200, remoteAddress=/0:0:0:0:0:0:0:1:43783}" , 
"stacktrace": ["java.io.IOException: Удаленный хост принудительно разорвал существующее подключение",
"at sun.nio.ch.SocketDispatcher.read0(Native Method) ~[?:?]",
"at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43) ~[?:?]",
"at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276) ~[?:?]",
"at sun.nio.ch.IOUtil.read(IOUtil.java:245) ~[?:?]",
"at sun.nio.ch.IOUtil.read(IOUtil.java:223) ~[?:?]",
"at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358) ~[?:?]",
"at io.netty.buffer.UnpooledHeapByteBuf.setBytes(UnpooledHeapByteBuf.java:291) ~[netty-buffer-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132) ~[netty-buffer-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:347) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:656) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:556) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:510) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:470) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:909) [netty-common-4.1.32.Final.jar:4.1.32.Final]",
"at java.lang.Thread.run(Thread.java:835) [?:?]"] }
{"type": "server", "timestamp": "2019-07-09T08:29:54,423+1000", "level": "WARN", "component": "o.e.h.AbstractHttpServerTransport", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "caught exception while handling client http traffic, closing connection Netty4HttpChannel{localAddress=/0:0:0:0:0:0:0:1:9200, remoteAddress=/0:0:0:0:0:0:0:1:43682}" , 
"stacktrace": ["java.io.IOException: Удаленный хост принудительно разорвал существующее подключение",
"at sun.nio.ch.SocketDispatcher.read0(Native Method) ~[?:?]",
"at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43) ~[?:?]",
"at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276) ~[?:?]",
"at sun.nio.ch.IOUtil.read(IOUtil.java:245) ~[?:?]",
"at sun.nio.ch.IOUtil.read(IOUtil.java:223) ~[?:?]",
"at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358) ~[?:?]",
"at io.netty.buffer.UnpooledHeapByteBuf.setBytes(UnpooledHeapByteBuf.java:291) ~[netty-buffer-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132) ~[netty-buffer-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:347) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:656) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:556) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:510) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:470) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:909) [netty-common-4.1.32.Final.jar:4.1.32.Final]",
"at java.lang.Thread.run(Thread.java:835) [?:?]"] }
{"type": "server", "timestamp": "2019-07-09T08:29:54,431+1000", "level": "WARN", "component": "o.e.h.AbstractHttpServerTransport", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "caught exception while handling client http traffic, closing connection Netty4HttpChannel{localAddress=/127.0.0.1:9200, remoteAddress=/127.0.0.1:38372}" , 
"stacktrace": ["java.io.IOException: Программа на вашем хост-компьютере разорвала установленное подключение",
"at sun.nio.ch.SocketDispatcher.read0(Native Method) ~[?:?]",
"at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43) ~[?:?]",
"at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276) ~[?:?]",
"at sun.nio.ch.IOUtil.read(IOUtil.java:245) ~[?:?]",
"at sun.nio.ch.IOUtil.read(IOUtil.java:223) ~[?:?]",
"at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358) ~[?:?]",
"at io.netty.buffer.UnpooledHeapByteBuf.setBytes(UnpooledHeapByteBuf.java:291) ~[netty-buffer-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132) ~[netty-buffer-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:347) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:656) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:556) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:510) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:470) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:909) [netty-common-4.1.32.Final.jar:4.1.32.Final]",
"at java.lang.Thread.run(Thread.java:835) [?:?]"] }
{"type": "server", "timestamp": "2019-07-09T08:29:54,570+1000", "level": "WARN", "component": "o.e.h.AbstractHttpServerTransport", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "caught exception while handling client http traffic, closing connection Netty4HttpChannel{localAddress=/0:0:0:0:0:0:0:1:9200, remoteAddress=/0:0:0:0:0:0:0:1:43484}" , 
"stacktrace": ["java.io.IOException: Удаленный хост принудительно разорвал существующее подключение",
"at sun.nio.ch.SocketDispatcher.read0(Native Method) ~[?:?]",
"at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43) ~[?:?]",
"at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276) ~[?:?]",
"at sun.nio.ch.IOUtil.read(IOUtil.java:245) ~[?:?]",
"at sun.nio.ch.IOUtil.read(IOUtil.java:223) ~[?:?]",
"at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358) ~[?:?]",
"at io.netty.buffer.UnpooledHeapByteBuf.setBytes(UnpooledHeapByteBuf.java:291) ~[netty-buffer-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132) ~[netty-buffer-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:347) ~[netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:148) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:656) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:556) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:510) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:470) [netty-transport-4.1.32.Final.jar:4.1.32.Final]",
"at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:909) [netty-common-4.1.32.Final.jar:4.1.32.Final]",
"at java.lang.Thread.run(Thread.java:835) [?:?]"] }
{"type": "server", "timestamp": "2019-07-09T08:29:57,338+1000", "level": "INFO", "component": "o.e.c.m.MetaDataIndexTemplateService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "adding template [.management-beats] for index patterns [.management-beats]"  }
{"type": "server", "timestamp": "2019-07-09T08:30:18,012+1000", "level": "INFO", "component": "o.e.m.j.JvmGcMonitorService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "[gc][4795] overhead, spent [352ms] collecting in the last [1s]"  }
{"type": "server", "timestamp": "2019-07-09T08:39:43,329+1000", "level": "INFO", "component": "o.e.n.Node", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "stopping ..."  }
{"type": "server", "timestamp": "2019-07-09T08:39:43,980+1000", "level": "INFO", "component": "o.e.x.w.WatcherService", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "stopping watch service, reason [shutdown initiated]"  }
{"type": "server", "timestamp": "2019-07-09T08:39:44,837+1000", "level": "INFO", "component": "o.e.x.m.p.l.CppLogMessageHandler", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "[controller/240332] [Main.cc@148] Ml controller exiting"  }
{"type": "server", "timestamp": "2019-07-09T08:39:45,348+1000", "level": "INFO", "component": "o.e.x.m.p.NativeController", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "Native controller process has stopped - no new native processes can be started"  }
{"type": "server", "timestamp": "2019-07-09T08:39:45,422+1000", "level": "WARN", "component": "o.e.i.s.RetentionLeaseSyncAction", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "[elastalert_status_past][0] retention lease background sync failed" , 
"stacktrace": ["org.elasticsearch.transport.SendRequestTransportException: [elasticsearch01][127.0.0.1:9300][indices:admin/seq_no/retention_lease_background_sync[p]]",
"at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:645) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.xpack.security.transport.SecurityServerTransportInterceptor$1.sendRequest(SecurityServerTransportInterceptor.java:137) ~[?:?]",
"at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:543) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:531) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performAction(TransportReplicationAction.java:864) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performLocalAction(TransportReplicationAction.java:815) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.doRun(TransportReplicationAction.java:802) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:171) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:100) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:145) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.xpack.security.action.filter.SecurityActionFilter.apply(SecurityActionFilter.java:123) ~[?:?]",
"at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:143) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:121) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:64) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.index.seqno.RetentionLeaseBackgroundSyncAction.backgroundSync(RetentionLeaseBackgroundSyncAction.java:111) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.indices.cluster.IndicesClusterStateService$1.backgroundSync(IndicesClusterStateService.java:175) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.index.shard.IndexShard.syncRetentionLeases(IndexShard.java:2063) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.index.IndexService.lambda$sync$11(IndexService.java:814) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.index.shard.IndexShard.lambda$runUnderPrimaryPermit$17(IndexShard.java:2585) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:61) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.index.shard.IndexShard.lambda$wrapPrimaryOperationPermitListener$14(IndexShard.java:2538) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:61) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:269) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.index.shard.IndexShardOperationPermits.acquire(IndexShardOperationPermits.java:236) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.index.shard.IndexShard.acquirePrimaryOperationPermit(IndexShard.java:2513) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.index.shard.IndexShard.runUnderPrimaryPermit(IndexShard.java:2589) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.index.IndexService.sync(IndexService.java:811) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.index.IndexService.syncRetentionLeases(IndexService.java:794) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.index.IndexService.access$800(IndexService.java:99) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.index.IndexService$AsyncRetentionLeaseSyncTask.runInternal(IndexService.java:975) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.common.util.concurrent.AbstractAsyncTask.run(AbstractAsyncTask.java:141) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]",
"at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]",
"at java.lang.Thread.run(Thread.java:835) [?:?]",
"Caused by: org.elasticsearch.transport.TransportException: TransportService is closed stopped can't send request",
"at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:627) ~[elasticsearch-7.1.1.jar:7.1.1]",
"... 35 more"] }
{"type": "server", "timestamp": "2019-07-09T08:39:47,621+1000", "level": "DEBUG", "component": "o.e.a.a.c.n.s.TransportNodesStatsAction", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "failed to execute on node [UX-HdPY5Q0iJLIzpq8XKpw]" , 
"stacktrace": ["org.elasticsearch.transport.SendRequestTransportException: [elasticsearch01][127.0.0.1:9300][cluster:monitor/nodes/stats[n]]",
"at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:645) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.xpack.security.transport.SecurityServerTransportInterceptor$1.sendRequest(SecurityServerTransportInterceptor.java:137) ~[?:?]",
"at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:543) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:531) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.start(TransportNodesAction.java:182) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.action.support.nodes.TransportNodesAction.doExecute(TransportNodesAction.java:82) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.action.support.nodes.TransportNodesAction.doExecute(TransportNodesAction.java:51) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:145) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.xpack.security.action.filter.SecurityActionFilter.apply(SecurityActionFilter.java:123) ~[?:?]",
"at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:143) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:121) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:64) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.client.node.NodeClient.executeLocally(NodeClient.java:83) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.client.node.NodeClient.doExecute(NodeClient.java:72) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:393) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.client.support.AbstractClient$ClusterAdmin.execute(AbstractClient.java:682) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.client.support.AbstractClient$ClusterAdmin.nodesStats(AbstractClient.java:778) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.cluster.InternalClusterInfoService.updateNodeStats(InternalClusterInfoService.java:248) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.cluster.InternalClusterInfoService.refresh(InternalClusterInfoService.java:284) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.cluster.InternalClusterInfoService.maybeRefresh(InternalClusterInfoService.java:269) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.cluster.InternalClusterInfoService.access$200(InternalClusterInfoService.java:65) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.cluster.InternalClusterInfoService$SubmitReschedulingClusterInfoUpdatedJob.lambda$run$0(InternalClusterInfoService.java:220) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]",
"at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]",
"at java.lang.Thread.run(Thread.java:835) [?:?]",
"Caused by: org.elasticsearch.transport.TransportException: TransportService is closed stopped can't send request",
"at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:627) ~[elasticsearch-7.1.1.jar:7.1.1]",
"... 25 more"] }
{"type": "server", "timestamp": "2019-07-09T08:39:47,622+1000", "level": "DEBUG", "component": "o.e.a.a.i.s.TransportIndicesStatsAction", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "failed to execute [indices:monitor/stats] on node [UX-HdPY5Q0iJLIzpq8XKpw]" , 
"stacktrace": ["org.elasticsearch.transport.SendRequestTransportException: [elasticsearch01][127.0.0.1:9300][indices:monitor/stats[n]]",
"at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:645) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.xpack.security.transport.SecurityServerTransportInterceptor$1.sendRequest(SecurityServerTransportInterceptor.java:137) ~[?:?]",
"at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:543) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:518) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.action.support.broadcast.node.TransportBroadcastByNodeAction$AsyncAction.sendNodeRequest(TransportBroadcastByNodeAction.java:314) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.action.support.broadcast.node.TransportBroadcastByNodeAction$AsyncAction.start(TransportBroadcastByNodeAction.java:303) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.action.support.broadcast.node.TransportBroadcastByNodeAction.doExecute(TransportBroadcastByNodeAction.java:226) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.action.support.broadcast.node.TransportBroadcastByNodeAction.doExecute(TransportBroadcastByNodeAction.java:77) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:145) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.xpack.security.action.filter.SecurityActionFilter.apply(SecurityActionFilter.java:123) ~[?:?]",
"at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:143) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:121) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:64) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.client.node.NodeClient.executeLocally(NodeClient.java:83) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.client.node.NodeClient.doExecute(NodeClient.java:72) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:393) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.client.support.AbstractClient$IndicesAdmin.execute(AbstractClient.java:1213) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.client.support.AbstractClient$IndicesAdmin.stats(AbstractClient.java:1529) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.cluster.InternalClusterInfoService.updateIndicesStats(InternalClusterInfoService.java:262) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.cluster.InternalClusterInfoService.refresh(InternalClusterInfoService.java:313) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.cluster.InternalClusterInfoService.maybeRefresh(InternalClusterInfoService.java:269) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.cluster.InternalClusterInfoService.access$200(InternalClusterInfoService.java:65) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.cluster.InternalClusterInfoService$SubmitReschedulingClusterInfoUpdatedJob.lambda$run$0(InternalClusterInfoService.java:220) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:681) ~[elasticsearch-7.1.1.jar:7.1.1]",
"at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]",
"at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]",
"at java.lang.Thread.run(Thread.java:835) [?:?]",
"Caused by: org.elasticsearch.transport.TransportException: TransportService is closed stopped can't send request",
"at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:627) ~[elasticsearch-7.1.1.jar:7.1.1]",
"... 26 more"] }
{"type": "server", "timestamp": "2019-07-09T08:39:50,200+1000", "level": "INFO", "component": "o.e.n.Node", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "stopped"  }
{"type": "server", "timestamp": "2019-07-09T08:39:50,229+1000", "level": "INFO", "component": "o.e.n.Node", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "closing ..."  }
{"type": "server", "timestamp": "2019-07-09T08:39:51,035+1000", "level": "INFO", "component": "o.e.n.Node", "cluster.name": "mongushSIEM", "node.name": "elasticsearch01", "cluster.uuid": "0Iesw0zBRS25JqFdm-TcLQ", "node.id": "UX-HdPY5Q0iJLIzpq8XKpw",  "message": "closed"  }
